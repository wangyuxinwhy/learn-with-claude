# Text Diversity Metrics

探索如何衡量 LLM 输出的多样性。

## 核心问题

同一个 prompt 采样多次，如何量化这些回复的"多样性"？

## 多样性的三个层面

| 层面 | 关注点 | 例子 |
|------|--------|------|
| 词法 | 用了哪些词 | "猫追狗" vs "猫追鼠" |
| 句法 | 词的组合方式 | "猫追狗" vs "狗追猫" |
| 语义 | 表达的含义 | "天气好" vs "适合户外" |

## 指标体系

### Jaccard 相似度

最简单的词法度量：交集 / 并集

```
Jaccard(A, B) = |A ∩ B| / |A ∪ B|
```

**局限**：忽略词频，"苹果 苹果 苹果" 和 "苹果" 被视为相同。

### 余弦相似度

用词袋向量表示文本，计算向量夹角：

```
cos(A, B) = (A · B) / (||A|| × ||B||)
```

**优势**：保留词频，消除长度影响。

### N-gram

捕捉词序信息。"猫追狗" 的 bigrams：{猫追, 追狗}

**洞察**："猫追狗" 和 "狗追猫" 词袋相同，但 bigrams 完全不同。

### Distinct-n

整体统计独特 n-gram 的比例：

```
Distinct-n = 独特 n-gram 数 / 总 n-gram 数
```

**特点**：O(n) 复杂度，直接衡量词汇/搭配丰富度。

### BLEU

机器翻译评估指标，核心问"生成的对不对"（Precision）：

1. **Modified Precision**：每个 n-gram 匹配数不超过参考中出现次数
2. **几何平均**：综合 1-4 gram，任一为 0 则整体为 0
3. **Brevity Penalty**：惩罚过短的生成

```
BLEU = BP × exp(Σ wₙ log pₙ)
```

### ROUGE

文本摘要评估指标，核心问"有没有漏"（Recall）：

```
ROUGE-N = 参考中被匹配的 n-gram 数 / 参考中总 n-gram 数
```

### Self-* 多样性

将相似度指标转换为多样性指标：

```
多样性 = 1 - 平均两两相似度
```

## 数学洞察

**两两距离 vs 到质心距离**

设有 n 个向量 x₁, x₂, ..., xₙ，质心 μ = (1/n) Σxᵢ

- **方差 V** = (1/n) Σ||xᵢ - μ||²（到质心的平均平方距离）
- **D** = (1/n²) ΣΣ||xᵢ - xⱼ||²（两两平均平方距离）

推导得：**D = 2V**

**结论**：两种方法衡量同一个几何性质（分散程度），选 O(n) 的方差计算。

## 指标选择

本项目实现的组合：

| 指标 | 层面 | 方法 | 复杂度 |
|------|------|------|--------|
| Pairwise-Jaccard | 词法 | 两两比较 | O(n²) |
| Distinct-2 | 句法 | 整体统计 | O(n) |
| Self-BLEU | 句法 | 1 vs n-1 | O(n) |

## Rust 学习收获

- `HashSet` / `HashMap` 集合操作
- 迭代器链：`split_whitespace()`, `collect()`, `combinations()`, `windows()`
- 类型转换与自动解引用
- Clippy 和 Rustfmt 工具链
