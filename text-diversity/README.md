# Text Diversity Metrics

探索如何衡量 LLM 输出的多样性。

## 核心问题

同一个 prompt 采样多次，如何量化这些回复的"多样性"？

## 多样性的三个层面

| 层面 | 关注点 | 例子 |
|------|--------|------|
| 词法 | 用了哪些词 | "猫追狗" vs "猫追鼠" |
| 句法 | 词的组合方式 | "猫追狗" vs "狗追猫" |
| 语义 | 表达的含义 | "天气好" vs "适合户外" |

## 指标体系

### Jaccard 相似度

最简单的词法度量：交集 / 并集

$$Jaccard(A, B) = \frac{|A \cap B|}{|A \cup B|}$$

**局限**：忽略词频，"苹果 苹果 苹果" 和 "苹果" 被视为相同。

### 余弦相似度

用词袋向量表示文本，计算向量夹角：

$$\cos(A, B) = \frac{A \cdot B}{\|A\| \times \|B\|}$$

**优势**：保留词频，消除长度影响。

### N-gram

捕捉词序信息。"猫追狗" 的 bigrams：{猫追, 追狗}

**洞察**："猫追狗" 和 "狗追猫" 词袋相同，但 bigrams 完全不同。

### Distinct-n

整体统计独特 n-gram 的比例：

$$Distinct\text{-}n = \frac{\text{独特 n-gram 数}}{\text{总 n-gram 数}}$$

**特点**：O(n) 复杂度，直接衡量词汇/搭配丰富度。

### BLEU

机器翻译评估指标，核心问"生成的对不对"（Precision）：

1. **Modified Precision**：每个 n-gram 匹配数不超过参考中出现次数
2. **几何平均**：综合 1-4 gram，任一为 0 则整体为 0
3. **Brevity Penalty**：惩罚过短的生成

$$BLEU = BP \times \exp\left(\sum_n w_n \log p_n\right)$$

### ROUGE

文本摘要评估指标，核心问"有没有漏"（Recall）：

$$ROUGE\text{-}N = \frac{\text{参考中被匹配的 n-gram 数}}{\text{参考中总 n-gram 数}}$$

## 数学洞察

**两两距离 vs 到质心距离**

设有 n 个向量 $x_1, x_2, ..., x_n$，质心 $\mu = \frac{1}{n} \sum_i x_i$

- **方差** $V = \frac{1}{n} \sum_i \|x_i - \mu\|^2$（到质心的平均平方距离）
- **两两距离** $D = \frac{1}{n^2} \sum_i \sum_j \|x_i - x_j\|^2$（两两平均平方距离）

推导得：$D = 2V$

**结论**：两种方法衡量同一个几何性质（分散程度），选 O(n) 的方差计算。

## 指标选择

本项目实现的组合：

| 指标 | 层面 | 方法 | 复杂度 |
|------|------|------|--------|
| Pairwise-Jaccard | 词法 | 两两比较 | O(n²) |
| Distinct-2 | 句法 | 整体统计 | O(n) |
| Self-BLEU | 句法 | 1 vs n-1 | O(n) |

## 实验结果

使用 Claude 系列模型（Haiku / Sonnet / Opus）在三种场景下各采样 5 次，对比输出多样性。

### 实验 1：事实性场景（介绍唐朝）

| 指标 | Haiku | Sonnet | Opus |
|------|-------|--------|------|
| Pairwise-Jaccard | **0.578** | 0.526 | 0.381 |
| Distinct-1 | **0.397** | 0.370 | 0.318 |
| Distinct-2 | **0.663** | 0.551 | 0.421 |
| Self-BLEU (相似度) | **0.415** | 0.549 | 0.789 |

### 实验 2：创意性场景（悬疑小说开头）

| 指标 | Haiku | Sonnet | Opus |
|------|-------|--------|------|
| Pairwise-Jaccard | **0.913** | 0.896 | 0.843 |
| Distinct-1 | 0.679 | **0.708** | 0.569 |
| Distinct-2 | **0.971** | 0.936 | 0.876 |
| Self-BLEU (相似度) | **0.000** | 0.044 | 0.162 |

### 实验 3：约束性场景（客服回复，带指南）

| 指标 | Haiku | Sonnet | Opus |
|------|-------|--------|------|
| Pairwise-Jaccard | 拒绝执行 | **0.406** | 0.178 |
| Distinct-1 | - | **0.273** | 0.207 |
| Distinct-2 | - | **0.523** | 0.292 |
| Self-BLEU (相似度) | - | **0.577** | 0.937 |

### 发现

**模型规模与多样性负相关**：在所有场景下，Haiku > Sonnet > Opus

**场景影响多样性**：创意 > 事实 > 约束

| 场景 | Opus Pairwise-Jaccard | Opus Self-BLEU |
|------|----------------------|----------------|
| 悬疑小说（创意） | 0.843 | 0.162 |
| 唐朝介绍（事实） | 0.381 | 0.789 |
| 客服回复（约束） | 0.178 | 0.937 |

**其他发现**：
- Haiku 拒绝执行客服角色扮演任务，小模型对指令的灵活性较差
- Opus 在约束场景下 5 个回复几乎一模一样（Self-BLEU 0.937）
- 更大的模型输出更"标准化"，对"正确答案"有更强的收敛性

## Rust 学习收获

- `HashSet` / `HashMap` 集合操作
- 迭代器链：`split_whitespace()`, `collect()`, `combinations()`, `windows()`
- 类型转换与自动解引用
- Clippy 和 Rustfmt 工具链
